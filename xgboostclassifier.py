# -*- coding: utf-8 -*-
"""XGBoostClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i7FmzPNvPEMRHAEbA5EwYMGKEm1sQuUi
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

import xgboost as xgb

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

df=pd.read_csv("https://raw.githubusercontent.com/ezioauditore-tech/AI/main/datasets/datasets_228_482_diabetes.csv")

df.describe()

df

df.shape

df.isnull().sum()

x_train=df.iloc[:,:-1].values #his selects all columns up to, but not including, the last column.
y_train=df.iloc[:,-1].values # last column value if -2 means second last column

x_train
y_train

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.20)

model_xgb=XGBClassifier()
from sklearn.model_selection import GridSearchCV
param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0]
}
grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, scoring='accuracy', cv=5, verbose=5)

grid_search.fit(x_train, y_train)
print("best parameters",grid_search.best_params_)
print("best acc",grid_search.best_score_)

model=XGBClassifier(learning_rate=0.01,min_child_weight=5,random_state=1,max_depth=3,max_leaves=4)
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

acc=accuracy_score(y_test,y_pred)*100
print(acc)

